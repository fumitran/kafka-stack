"""
Li·ªát k√™ to√†n b·ªô th√¥ng tin clusters t·ª´ Kafka UI v√† ghi ra file CSV.
"""

import csv
import json
import os
from typing import Any, Dict, List

import sys
import os
# Add src directory to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from utils.kafka_ui_client import KafkaUIClient
from config import KafkaUIConfig


def ensure_export_dir() -> str:
    """ƒê·∫£m b·∫£o t·ªìn t·∫°i th∆∞ m·ª•c export, tr·∫£ v·ªÅ ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi."""
    # Export directory ·ªü root c·ªßa project, kh√¥ng ph·∫£i trong src/
    base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    export_dir = os.path.join(base_dir, "export")
    os.makedirs(export_dir, exist_ok=True)
    return export_dir


def normalize_row(data: Dict[str, Any], fieldnames: List[str]) -> Dict[str, str]:
    """
    Chuy·ªÉn dict sang dict string cho CSV.
    - Gi√° tr·ªã None -> "".
    - List / Dict -> json.dumps.
    """
    row: Dict[str, str] = {}
    for key in fieldnames:
        value = data.get(key)
        if value is None:
            row[key] = ""
        elif isinstance(value, (dict, list)):
            row[key] = json.dumps(value, ensure_ascii=False)
        else:
            row[key] = str(value)
    return row


def export_clusters_to_csv(clusters: List[Dict[str, Any]], file_path: str) -> None:
    """Ghi danh s√°ch clusters ra file CSV."""
    if not clusters:
        print("Kh√¥ng c√≥ cluster n√†o ƒë·ªÉ export.")
        return

    # L·∫•y t·∫≠p h·ª£p t·∫•t c·∫£ key xu·∫•t hi·ªán trong c√°c cluster (ƒë·∫£m b·∫£o ƒë·ªß c·ªôt)
    fieldnames_set = set()
    for c in clusters:
        fieldnames_set.update(c.keys())

    # S·∫Øp x·∫øp c·ªôt, ∆∞u ti√™n m·ªôt s·ªë c·ªôt hay d√πng l√™n ƒë·∫ßu
    preferred_order = [
        "name",
        "status",
        "brokerCount",
        "topicCount",
        "onlinePartitionCount",
        "version",
        "readOnly",
    ]
    remaining = [f for f in sorted(fieldnames_set) if f not in preferred_order]
    fieldnames = [f for f in preferred_order if f in fieldnames_set] + remaining

    with open(file_path, mode="w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for c in clusters:
            writer.writerow(normalize_row(c, fieldnames))

    print(f"‚úÖ ƒê√£ export {len(clusters)} clusters ra file: {file_path}")


def main():
    """Main: g·ªçi Kafka UI v√† export clusters ra CSV."""
    # C·∫•u h√¨nh:
    #   - T·∫•t c·∫£ tham s·ªë (base_url, username/password, SESSION...) ƒë∆∞·ª£c c·∫•u h√¨nh trong file config.py
    #   - Ho·∫∑c qua bi·∫øn m√¥i tr∆∞·ªùng:
    #       KAFKA_UI_BASE_URL, KAFKA_UI_USERNAME, KAFKA_UI_PASSWORD, KAFKA_UI_SESSION, KAFKA_CLUSTER_NAME, ...
    config = KafkaUIConfig()
    client = KafkaUIClient(config)

    try:
        print("ƒêang l·∫•y danh s√°ch clusters t·ª´ Kafka UI...")
        clusters = client.get_clusters()
        print(f"L·∫•y ƒë∆∞·ª£c {len(clusters)} clusters.")

        export_dir = ensure_export_dir()
        output_file = os.path.join(export_dir, "cluster.csv")
        export_clusters_to_csv(clusters, output_file)
    except Exception as e:
        print(f"\n‚ùå L·ªói khi export clusters: {e}")
        print("\nüí° G·ª£i √Ω:")
        print("  1. ƒê·∫£m b·∫£o Kafka UI ƒëang ch·∫°y tr√™n http://localhost:8080")
        print("  2. Ki·ªÉm tra SESSION cookie ho·∫∑c username/password c√≥ ƒë√∫ng kh√¥ng")
        print("  3. Th·ª≠ g·ªçi tr·ª±c ti·∫øp API: curl http://localhost:8080/api/clusters")


if __name__ == "__main__":
    main()


